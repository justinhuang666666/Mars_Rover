# Mars_Rover_2022
## 1.Introduction
This project aims to design and construct a Mars rover for extra-terrestrial exploration. The rover system must be able to navigate itself in the test arena and build a map indicating the locations of aliens and their underground power infrastructure. The rover system must also autonomously avoid the alien and the infrastructure while running. In addition, the real-time system status should be displayed on the web application. The web application should have the capability of controlling the Rover remotely. Furthermore, there must be a system for powering the Rover from solar energy for long-term sustainable operation on Mars.
## 2.Design Hierarchy
The rover system consists of 6 modules: Control, Vision, Radar, Energy and Drive.
The control module is based on a Espressif 32-bit microcontroller. The eps32 provides on-board processing abilities and interfaces between submodules. The Vision module identifies and locates the alien and their infrastructure in the field of view using the Terasic D8M-GPIO camera and the FPGA. The FPGA communicates with control module via UART protocol. The controller reads serial data sequentially from the FPGA and updates the characteristics of aliens and the position of their infrastructure. Upon receipt of these information, the control module command the drive module for rover maneuver and obstacle avoidance. The radar module detects the underground alien infrastructure using the HB100. The module is directly connected to the analogue pin of esp32. When the signal level is above the threshold value, the controller records the current coordinates for further processing. The energy module provides the system with charged power bank using solar energy. The energy module should guarantee optimal power yield from the solar panel and high-power efficiency. Furthermore, the ESP32 has Wi-Fi functionality, making wireless communication between the rover and web server possible. The communication is based on the RTDB connection. The control module uploads the rover status and current position to database and receives commands from web applications for manual rover control. The highlight of the design is the use of Simultaneous localization and mapping (SLAM). The video is computed on Raspberry Pi 4B to generate point-cloud 3D map.

